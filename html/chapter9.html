<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第九章：高性能计算</title>
    <link rel="stylesheet" href="./assets/style.css">
    <link rel="stylesheet" href="./assets/highlight.css">
    <script src="./assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <ul class="nav-list"><li class=""><a href="./index.html">高级物理引擎实战教程</a></li><li class=""><a href="./chapter1.html">第一章：导论</a></li><li class=""><a href="./chapter2.html">第二章：拉格朗日视角（1）</a></li><li class=""><a href="./chapter3.html">第三章：拉格朗日视角（2）：有限元仿真</a></li><li class=""><a href="./chapter4.html">第四章：欧拉视角（1）</a></li><li class=""><a href="./chapter5.html">第五章：欧拉视角（2）：线性系统求解器</a></li><li class=""><a href="./chapter6.html">第六章：高级输送格式与等势面方法</a></li><li class=""><a href="./chapter7.html">第七章：混合欧拉-拉格朗日视角（1）</a></li><li class=""><a href="./chapter8.html">第八章：混合欧拉-拉格朗日视角（2）：物质点法</a></li><li class="active"><a href="./chapter9.html">第九章：高性能计算</a></li><li class=""><a href="./chapter10.html">第十章：可微编程与机器学习</a></li><li class=""><a href="./chapter8b.html">第八章：多重网格方法</a></li><li class=""><a href="./CLAUDE.html">Untitled</a></li><li class=""><a href="./old.html">Untitled</a></li></ul>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="_1">第九章：高性能计算</h1>
<p>本章深入探讨物理引擎的性能优化技术，从底层硬件架构到高层算法优化。我们将学习如何充分利用现代处理器的并行计算能力，设计高效的数据结构，以及实现可扩展的并行算法。通过本章的学习，读者将掌握构建高性能物理仿真系统所需的核心技术。</p>
<h2 id="91">9.1 处理器微架构</h2>
<h3 id="911-cpu">9.1.1 CPU流水线与超标量</h3>
<p>现代CPU采用流水线技术将指令执行分解为多个阶段，典型的五级流水线包括：</p>
<ol>
<li><strong>取指(Fetch)</strong>：从内存读取指令</li>
<li><strong>译码(Decode)</strong>：解析指令操作码和操作数</li>
<li><strong>执行(Execute)</strong>：在ALU中执行运算</li>
<li><strong>访存(Memory)</strong>：读写内存（如需要）</li>
<li><strong>回写(Write Back)</strong>：将结果写回寄存器</li>
</ol>
<p>超标量处理器能够在一个时钟周期内发射多条指令，现代CPU通常具有4-6个发射端口。指令级并行(ILP)的关键在于：</p>
<ul>
<li><strong>数据依赖性</strong>：后续指令依赖前面指令的结果</li>
<li><strong>控制依赖性</strong>：分支指令影响程序流</li>
<li><strong>结构冲突</strong>：多条指令竞争相同的执行单元</li>
</ul>
<p>为了提高ILP，编译器和程序员需要：</p>
<ul>
<li>展开循环减少分支</li>
<li>重排指令减少数据依赖</li>
<li>使用SIMD指令增加吞吐量</li>
</ul>
<h3 id="912-simd">9.1.2 SIMD指令集</h3>
<p>单指令多数据(SIMD)是提升数值计算性能的关键技术。主要的SIMD扩展包括：</p>
<p><strong>SSE/AVX系列</strong>：</p>
<ul>
<li>SSE：128位寄存器，4个float或2个double</li>
<li>AVX：256位寄存器，8个float或4个double  </li>
<li>AVX-512：512位寄存器，16个float或8个double</li>
</ul>
<p><strong>常用SIMD操作</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 加法：c = a + b</span>
<span class="n">__m256</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">_mm256_add_ps</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">);</span>

<span class="c1">// 乘加：d = a * b + c</span>
<span class="n">__m256</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">_mm256_fmadd_ps</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="c1">// 广播：将标量复制到向量所有位置</span>
<span class="n">__m256</span><span class="w"> </span><span class="n">vec</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="n">_mm256_set1_ps</span><span class="p">(</span><span class="n">scalar</span><span class="p">);</span>
</code></pre></div>

<p><strong>向量化考虑</strong>：</p>
<ul>
<li>数据对齐：使用<code>_mm_malloc</code>确保32字节对齐</li>
<li>避免分支：使用blend指令代替if-else</li>
<li>减少gather/scatter：连续内存访问效率最高</li>
</ul>
<h3 id="913">9.1.3 分支预测与投机执行</h3>
<p>现代CPU使用分支预测器猜测条件跳转的方向，典型预测准确率达95%以上。分支预测失败会导致流水线清空，损失10-20个时钟周期。</p>
<p><strong>优化策略</strong>：</p>
<ol>
<li><strong>减少分支</strong>：使用条件移动指令或位运算</li>
<li><strong>分支提示</strong>：使用<code>__builtin_expect</code>提供预测信息</li>
<li><strong>循环展开</strong>：减少循环边界检查</li>
<li><strong>模板化</strong>：将运行时分支转为编译时决策</li>
</ol>
<p><strong>投机执行风险</strong>：</p>
<ul>
<li>Spectre/Meltdown等安全漏洞</li>
<li>需要考虑侧信道攻击防护</li>
</ul>
<h3 id="914">9.1.4 乱序执行</h3>
<p>乱序执行允许CPU重排指令顺序以隐藏延迟：</p>
<p><strong>Tomasulo算法核心组件</strong>：</p>
<ul>
<li><strong>保留站</strong>：缓存等待执行的指令</li>
<li><strong>重排缓冲区(ROB)</strong>：维护程序顺序</li>
<li><strong>寄存器重命名</strong>：消除伪依赖</li>
</ul>
<p><strong>性能影响因素</strong>：</p>
<ul>
<li>指令窗口大小（典型200-300条）</li>
<li>执行端口数量和类型</li>
<li>内存消歧(memory disambiguation)能力</li>
</ul>
<p><strong>编程建议</strong>：</p>
<ul>
<li>增加指令间距离，给CPU更多重排空间</li>
<li>使用restrict关键字帮助编译器优化</li>
<li>避免长依赖链</li>
</ul>
<h2 id="92">9.2 内存层级</h2>
<h3 id="921">9.2.1 缓存结构与大小</h3>
<p>现代CPU的缓存层次结构：</p>
<p>| 级别 | 大小 | 延迟 | 带宽 |</p>
<table>
<thead>
<tr>
<th>级别</th>
<th>大小</th>
<th>延迟</th>
<th>带宽</th>
</tr>
</thead>
<tbody>
<tr>
<td>L1-D</td>
<td>32KB</td>
<td>4-5 cycles</td>
<td>~100 GB/s</td>
</tr>
<tr>
<td>L1-I</td>
<td>32KB</td>
<td>4-5 cycles</td>
<td>~100 GB/s</td>
</tr>
<tr>
<td>L2</td>
<td>256KB-1MB</td>
<td>12-15 cycles</td>
<td>~50 GB/s</td>
</tr>
<tr>
<td>L3</td>
<td>8MB-32MB</td>
<td>30-40 cycles</td>
<td>~30 GB/s</td>
</tr>
<tr>
<td>DRAM</td>
<td>16GB+</td>
<td>100-300 cycles</td>
<td>~20 GB/s</td>
</tr>
</tbody>
</table>
<p><strong>缓存组织</strong>：</p>
<ul>
<li><strong>组相联</strong>：L1通常8路，L2/L3可达16-20路</li>
<li><strong>缓存行</strong>：64字节，是缓存传输的基本单位</li>
<li><strong>包含性</strong>：L3通常包含L1/L2的内容</li>
</ul>
<p><strong>缓存优化原则</strong>：</p>
<ol>
<li><strong>空间局部性</strong>：连续访问相邻数据</li>
<li><strong>时间局部性</strong>：重复访问相同数据</li>
<li><strong>工作集大小</strong>：保持热数据在缓存内</li>
</ol>
<h3 id="922">9.2.2 缓存行与伪共享</h3>
<p>伪共享(False Sharing)是多核编程的常见性能陷阱：</p>
<div class="codehilite"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">BadLayout</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">thread1_data</span><span class="p">;</span><span class="w">  </span><span class="c1">// 线程1写</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">thread2_data</span><span class="p">;</span><span class="w">  </span><span class="c1">// 线程2写，但在同一缓存行！</span>
<span class="p">};</span>

<span class="k">struct</span><span class="w"> </span><span class="nc">GoodLayout</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">alignas</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">thread1_data</span><span class="p">;</span><span class="w">  </span><span class="c1">// 独占缓存行</span>
<span class="w">    </span><span class="k">alignas</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">thread2_data</span><span class="p">;</span><span class="w">  </span><span class="c1">// 独占缓存行</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>检测方法</strong>：</p>
<ul>
<li>使用perf监控缓存失效率</li>
<li>Intel VTune的False Sharing检测器</li>
<li>手动padding或使用<code>alignas</code></li>
</ul>
<p><strong>缓存行优化技巧</strong>：</p>
<ul>
<li>将只读数据分离到独立缓存行</li>
<li>使用本地变量累积，最后写回</li>
<li>考虑数据布局的缓存友好性</li>
</ul>
<h3 id="923-tlb">9.2.3 TLB与页表</h3>
<p>转换查找缓冲器(TLB)缓存虚拟地址到物理地址的映射：</p>
<p><strong>TLB层次</strong>：</p>
<ul>
<li>L1 DTLB：64-128项，4KB页</li>
<li>L1 ITLB：64-128项，指令页</li>
<li>L2 TLB：512-1536项，统一</li>
<li>大页支持：2MB/1GB页减少TLB压力</li>
</ul>
<p><strong>TLB优化</strong>：</p>
<ol>
<li><strong>使用大页</strong>：<code>madvise(MADV_HUGEPAGE)</code></li>
<li><strong>减少工作集</strong>：避免稀疏访问模式</li>
<li><strong>页面着色</strong>：控制物理页分配减少冲突</li>
</ol>
<p><strong>页表遍历开销</strong>：</p>
<ul>
<li>4级页表需要4次内存访问</li>
<li>使用大页减少页表级数</li>
<li>考虑NUMA下的页面放置</li>
</ul>
<h3 id="924-numa">9.2.4 NUMA架构</h3>
<p>非统一内存访问(NUMA)是多插槽系统的标准架构：</p>
<p><strong>NUMA特征</strong>：</p>
<ul>
<li>每个CPU有本地内存控制器</li>
<li>访问远程内存延迟高50-100%</li>
<li>QPI/UPI互连带宽有限</li>
</ul>
<p><strong>NUMA感知编程</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 绑定线程到NUMA节点</span>
<span class="n">numa_run_on_node</span><span class="p">(</span><span class="n">node_id</span><span class="p">);</span>

<span class="c1">// 在指定节点分配内存</span>
<span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">numa_alloc_onnode</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">node_id</span><span class="p">);</span>

<span class="c1">// 内存访问模式优化</span>
<span class="cp">#pragma omp parallel for schedule(static)</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 确保线程访问本地数据</span>
<span class="w">    </span><span class="n">process_local_data</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>NUMA优化策略</strong>：</p>
<ul>
<li>First-touch策略：首次访问的线程所在节点分配页面</li>
<li>显式内存绑定：使用<code>numactl</code>或API</li>
<li>避免远程访问：数据分区对齐NUMA拓扑</li>
</ul>
<h2 id="93">9.3 性能分析与优化</h2>
<h3 id="931-roofline">9.3.1 Roofline模型</h3>
<p>Roofline模型将程序性能上限可视化为计算能力和内存带宽的函数：</p>
<p><strong>性能上限计算</strong>：
$$\text{Performance} = \min(\text{Peak FLOPS}, \text{Arithmetic Intensity} \times \text{Bandwidth})$$
其中算术强度(Arithmetic Intensity) = FLOPs / Bytes</p>
<p><strong>典型算术强度</strong>：</p>
<ul>
<li>DAXPY (y = ax + y): 2 FLOPs / 24 Bytes = 0.083</li>
<li>矩阵乘法: O(n³) FLOPs / O(n²) Bytes = O(n)</li>
<li>模板计算: 取决于模板大小和重用</li>
</ul>
<p><strong>优化方向判断</strong>：</p>
<ul>
<li>AI &lt; 机器平衡点：内存带宽受限，需要数据重用</li>
<li>AI &gt; 机器平衡点：计算受限，需要向量化/并行化</li>
</ul>
<h3 id="932-vs">9.3.2 带宽vs计算瓶颈</h3>
<p>识别性能瓶颈的关键指标：</p>
<p><strong>内存带宽受限特征</strong>：</p>
<ul>
<li>CPU利用率低（等待内存）</li>
<li>L3缓存未命中率高</li>
<li>内存控制器接近饱和</li>
</ul>
<p><strong>计算受限特征</strong>：</p>
<ul>
<li>CPU利用率接近100%</li>
<li>指令吞吐量接近峰值</li>
<li>缓存命中率高</li>
</ul>
<p><strong>平衡优化策略</strong>：</p>
<ol>
<li><strong>提高算术强度</strong>：循环阻塞、数据重用</li>
<li><strong>减少内存流量</strong>：压缩数据结构、精度权衡</li>
<li><strong>隐藏内存延迟</strong>：预取、软件流水线</li>
</ol>
<h3 id="933">9.3.3 性能计数器</h3>
<p>硬件性能计数器提供详细的执行信息：</p>
<p><strong>关键性能事件</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 使用perf统计缓存失效</span>
perf<span class="w"> </span>stat<span class="w"> </span>-e<span class="w"> </span>cache-misses,cache-references<span class="w"> </span>./program

<span class="c1"># 监控分支预测</span>
perf<span class="w"> </span>stat<span class="w"> </span>-e<span class="w"> </span>branch-misses,branch-instructions<span class="w"> </span>./program

<span class="c1"># 内存带宽测量</span>
perf<span class="w"> </span>stat<span class="w"> </span>-e<span class="w"> </span>uncore_imc/data_reads/,uncore_imc/data_writes/<span class="w"> </span>./program
</code></pre></div>

<p><strong>常用计数器</strong>：</p>
<ul>
<li>Instructions Per Cycle (IPC)</li>
<li>Cache hit/miss rates</li>
<li>TLB miss rates</li>
<li>Branch misprediction rate</li>
<li>Memory bandwidth utilization</li>
</ul>
<p><strong>分析工具链</strong>：</p>
<ul>
<li>Linux perf：轻量级，内置内核</li>
<li>Intel VTune：详细的微架构分析</li>
<li>AMD uProf：AMD平台优化</li>
<li>NVIDIA Nsight：GPU性能分析</li>
</ul>
<h3 id="934-profile">9.3.4 Profile工具使用</h3>
<p><strong>采样分析(Sampling Profiler)</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 记录性能数据</span>
perf<span class="w"> </span>record<span class="w"> </span>-g<span class="w"> </span>./simulation

<span class="c1"># 生成火焰图</span>
perf<span class="w"> </span>script<span class="w"> </span><span class="p">|</span><span class="w"> </span>flamegraph.pl<span class="w"> </span>&gt;<span class="w"> </span>flame.svg

<span class="c1"># 查看热点函数</span>
perf<span class="w"> </span>report<span class="w"> </span>--stdio
</code></pre></div>

<p><strong>追踪分析(Tracing Profiler)</strong>：</p>
<ul>
<li>精确的函数调用时序</li>
<li>更高的开销</li>
<li>适合分析复杂交互</li>
</ul>
<p><strong>优化工作流</strong>：</p>
<ol>
<li><strong>识别热点</strong>：找到占用时间最多的函数</li>
<li><strong>分析瓶颈</strong>：确定是计算、内存还是同步</li>
<li><strong>针对优化</strong>：应用相应的优化技术</li>
<li><strong>验证效果</strong>：对比优化前后性能</li>
</ol>
<h2 id="94">9.4 并行编程模型</h2>
<h3 id="941-openmp">9.4.1 共享内存并行(OpenMP)</h3>
<p>OpenMP是共享内存并行编程的事实标准，通过编译器指令实现并行化：</p>
<p><strong>基本并行结构</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="cp">#pragma omp parallel for</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">process</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w">  </span><span class="c1">// 自动分配给多个线程</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>高级OpenMP特性</strong>：</p>
<ol>
<li>
<p><strong>调度策略</strong>：
   - <code>static</code>：固定大小块分配，开销最小
   - <code>dynamic</code>：动态分配，适合负载不均
   - <code>guided</code>：递减块大小，平衡负载和开销
   - <code>runtime</code>：运行时通过环境变量决定</p>
</li>
<li>
<p><strong>归约操作</strong>：</p>
</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="kt">double</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="cp">#pragma omp parallel for reduction(+:sum)</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">array</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div>

<ol start="3">
<li><strong>同步原语</strong>：
   - <code>#pragma omp critical</code>：临界区
   - <code>#pragma omp atomic</code>：原子操作
   - <code>#pragma omp barrier</code>：栅栏同步</li>
</ol>
<p><strong>OpenMP优化技巧</strong>：</p>
<ul>
<li>避免false sharing：使用<code>firstprivate</code></li>
<li>减少同步开销：批量处理减少critical区域</li>
<li>NUMA感知：使用<code>proc_bind</code>和<code>places</code>子句</li>
</ul>
<h3 id="942-mpi">9.4.2 分布式内存(MPI)</h3>
<p>消息传递接口(MPI)是分布式内存并行的标准：</p>
<p><strong>基本通信模式</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 点对点通信</span>
<span class="n">MPI_Send</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">dest</span><span class="p">,</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
<span class="n">MPI_Recv</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>

<span class="c1">// 集合通信</span>
<span class="n">MPI_Bcast</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">root</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
<span class="n">MPI_Allreduce</span><span class="p">(</span><span class="o">&amp;</span><span class="n">local</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">global</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_SUM</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
</code></pre></div>

<p><strong>非阻塞通信</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">MPI_Request</span><span class="w"> </span><span class="n">request</span><span class="p">;</span>
<span class="n">MPI_Isend</span><span class="p">(</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="n">count</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">,</span><span class="w"> </span><span class="n">dest</span><span class="p">,</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">request</span><span class="p">);</span>
<span class="c1">// 计算与通信重叠</span>
<span class="n">do_computation</span><span class="p">();</span>
<span class="n">MPI_Wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">request</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
</code></pre></div>

<p><strong>MPI优化策略</strong>：</p>
<ol>
<li><strong>消息聚合</strong>：减少小消息的开销</li>
<li><strong>通信-计算重叠</strong>：使用非阻塞通信</li>
<li><strong>拓扑感知</strong>：匹配通信模式与网络拓扑</li>
<li><strong>负载均衡</strong>：动态任务分配</li>
</ol>
<h3 id="943-vs">9.4.3 任务并行vs数据并行</h3>
<p><strong>数据并行</strong>：</p>
<ul>
<li>相同操作应用于不同数据</li>
<li>SIMD、GPU天然适合</li>
<li>易于负载均衡</li>
<li>例：矩阵运算、图像处理</li>
</ul>
<p><strong>任务并行</strong>：</p>
<ul>
<li>不同任务同时执行</li>
<li>依赖关系复杂</li>
<li>负载均衡困难</li>
<li>例：流水线、DAG调度</li>
</ul>
<p><strong>混合并行模式</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="cp">#pragma omp parallel sections</span>
<span class="p">{</span>
<span class="w">    </span><span class="cp">#pragma omp section</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="n">compute_forces</span><span class="p">();</span><span class="w"> </span><span class="p">}</span><span class="w">     </span><span class="c1">// 任务1</span>

<span class="w">    </span><span class="cp">#pragma omp section  </span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="n">update_positions</span><span class="p">();</span><span class="w"> </span><span class="p">}</span><span class="w">   </span><span class="c1">// 任务2</span>
<span class="p">}</span>

<span class="cp">#pragma omp parallel for     </span><span class="c1">// 数据并行</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">apply_constraints</span><span class="p">(</span><span class="n">particles</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="944">9.4.4 负载均衡策略</h3>
<p><strong>静态负载均衡</strong>：</p>
<ul>
<li>编译时或启动时分配</li>
<li>开销小但灵活性差</li>
<li>适合规则计算</li>
</ul>
<p><strong>动态负载均衡</strong>：</p>
<ol>
<li><strong>工作池模式</strong>：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="nb">true</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">Task</span><span class="o">*</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_next_task</span><span class="p">();</span><span class="w">  </span><span class="c1">// 原子获取</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">task</span><span class="p">)</span><span class="w"> </span><span class="k">break</span><span class="p">;</span>
<span class="w">    </span><span class="n">process_task</span><span class="p">(</span><span class="n">task</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>

<ol start="2">
<li>
<p><strong>工作窃取(Work Stealing)</strong>：
- 每个线程维护本地队列
- 空闲线程从忙碌线程窃取任务
- Intel TBB、Cilk Plus实现</p>
</li>
<li>
<p><strong>层次分解</strong>：
- 递归划分问题
- 适合树形结构
- 自然负载均衡</p>
</li>
</ol>
<p><strong>负载均衡度量</strong>：
$$\text{Efficiency} = \frac{\text{Average Load}}{\text{Maximum Load}}$$</p>
<p>目标是使效率接近1.0</p>
<h2 id="95-gpu">9.5 GPU编程</h2>
<h3 id="951-gpu">9.5.1 GPU架构概述</h3>
<p>GPU采用SIMT(Single Instruction Multiple Thread)架构，与CPU的关键区别：</p>
<p><strong>架构特点</strong>：</p>
<ul>
<li>数千个简单核心 vs 几十个复杂核心</li>
<li>深度多线程隐藏内存延迟</li>
<li>高内存带宽（~1TB/s vs ~100GB/s）</li>
<li>有限的分支能力</li>
</ul>
<p><strong>GPU内存层次</strong>：
| 内存类型 | 大小 | 延迟 | 带宽 | 作用域 |</p>
<table>
<thead>
<tr>
<th>内存类型</th>
<th>大小</th>
<th>延迟</th>
<th>带宽</th>
<th>作用域</th>
</tr>
</thead>
<tbody>
<tr>
<td>寄存器</td>
<td>64KB/SM</td>
<td>1 cycle</td>
<td>极高</td>
<td>线程私有</td>
</tr>
<tr>
<td>共享内存</td>
<td>48-96KB/SM</td>
<td>~30 cycles</td>
<td>~2TB/s</td>
<td>Block共享</td>
</tr>
<tr>
<td>L1缓存</td>
<td>24-48KB/SM</td>
<td>~30 cycles</td>
<td>~1TB/s</td>
<td>自动管理</td>
</tr>
<tr>
<td>L2缓存</td>
<td>4-6MB</td>
<td>~200 cycles</td>
<td>~2TB/s</td>
<td>全局共享</td>
</tr>
<tr>
<td>全局内存</td>
<td>8-80GB</td>
<td>~400 cycles</td>
<td>~1TB/s</td>
<td>全局可见</td>
</tr>
</tbody>
</table>
<h3 id="952">9.5.2 线程组织</h3>
<p>CUDA/OpenCL的三级线程层次：</p>
<p><strong>Grid → Block → Thread</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// Kernel启动配置</span>
<span class="kt">dim3</span><span class="w"> </span><span class="nf">blockDim</span><span class="p">(</span><span class="mi">256</span><span class="p">);</span><span class="w">  </span><span class="c1">// 每个block 256线程</span>
<span class="kt">dim3</span><span class="w"> </span><span class="nb">gridDim</span><span class="p">((</span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">255</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">256</span><span class="p">);</span><span class="w">  </span><span class="c1">// 足够的blocks</span>
<span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="nb">gridDim</span><span class="p">,</span><span class="w"> </span><span class="nb">blockDim</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
</code></pre></div>

<p><strong>Warp执行模型</strong>：</p>
<ul>
<li>32个线程组成一个warp</li>
<li>Warp内线程锁步执行</li>
<li>分支导致线程发散(divergence)</li>
<li>合并内存访问提高带宽利用</li>
</ul>
<p><strong>线程同步</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="nf">__syncthreads</span><span class="p">();</span><span class="w">  </span><span class="c1">// Block内同步</span>
<span class="n">__syncwarp</span><span class="p">();</span><span class="w">     </span><span class="c1">// Warp内同步（隐式）</span>
<span class="c1">// Grid级同步需要kernel边界</span>
</code></pre></div>

<h3 id="953">9.5.3 内存合并访问</h3>
<p>内存合并是GPU性能的关键：</p>
<p><strong>合并条件</strong>：</p>
<ol>
<li>连续的线程访问连续的地址</li>
<li>起始地址对齐到128字节</li>
<li>访问大小为4、8或16字节</li>
</ol>
<p><strong>合并访问模式</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// Good: 合并访问</span>
<span class="n">data</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">value</span><span class="p">;</span>

<span class="c1">// Bad: 跨步访问</span>
<span class="n">data</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">stride</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">value</span><span class="p">;</span>

<span class="c1">// Bad: 随机访问  </span>
<span class="n">data</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">value</span><span class="p">;</span>
</code></pre></div>

<p><strong>优化技巧</strong>：</p>
<ul>
<li>使用共享内存转置数据</li>
<li>Structure of Arrays (SoA)布局</li>
<li>纹理内存处理非规则访问</li>
</ul>
<h3 id="954">9.5.4 占用率优化</h3>
<p>占用率(Occupancy)表示活跃warp数与最大warp数的比例：</p>
<p><strong>影响因素</strong>：</p>
<ol>
<li><strong>寄存器使用</strong>：每线程寄存器数×线程数 ≤ 总寄存器数</li>
<li><strong>共享内存</strong>：每block共享内存 ≤ 总共享内存</li>
<li><strong>Block大小</strong>：必须是warp大小的倍数</li>
</ol>
<p><strong>优化策略</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 使用launch bounds限制寄存器</span>
<span class="kr">__global__</span><span class="w"> </span><span class="nf">__launch_bounds__</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span>
<span class="kt">void</span><span class="w"> </span><span class="n">kernel</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 编译器将优化到指定的占用率</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>动态并行</strong>：</p>
<ul>
<li>从kernel内启动新kernel</li>
<li>适合不规则并行</li>
<li>注意启动开销</li>
</ul>
<p><strong>占用率计算</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">calc_occupancy</span><span class="p">(</span><span class="n">regs_per_thread</span><span class="p">,</span> <span class="n">shared_per_block</span><span class="p">,</span> <span class="n">threads_per_block</span><span class="p">):</span>
    <span class="n">max_warps_per_sm</span> <span class="o">=</span> <span class="mi">64</span>  <span class="c1"># 架构相关</span>
    <span class="n">max_regs_per_sm</span> <span class="o">=</span> <span class="mi">65536</span>
    <span class="n">max_shared_per_sm</span> <span class="o">=</span> <span class="mi">49152</span>

    <span class="n">warps_limited_by_regs</span> <span class="o">=</span> <span class="n">max_regs_per_sm</span> <span class="o">//</span> <span class="p">(</span><span class="n">regs_per_thread</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">blocks_limited_by_shared</span> <span class="o">=</span> <span class="n">max_shared_per_sm</span> <span class="o">//</span> <span class="n">shared_per_block</span>
    <span class="n">warps_limited_by_shared</span> <span class="o">=</span> <span class="n">blocks_limited_by_shared</span> <span class="o">*</span> <span class="p">(</span><span class="n">threads_per_block</span> <span class="o">//</span> <span class="mi">32</span><span class="p">)</span>

    <span class="n">active_warps</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">warps_limited_by_regs</span><span class="p">,</span> <span class="n">warps_limited_by_shared</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">active_warps</span> <span class="o">/</span> <span class="n">max_warps_per_sm</span>
</code></pre></div>

<h2 id="96">9.6 稀疏数据结构</h2>
<h3 id="961-spgridopenvdb">9.6.1 SPGrid与OpenVDB</h3>
<p><strong>SPGrid特点</strong>：</p>
<ul>
<li>利用虚拟内存的稀疏性</li>
<li>页面级别的存在性跟踪</li>
<li>适合均匀稀疏的数据</li>
</ul>
<p><strong>实现原理</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">template</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="n">dim</span><span class="o">&gt;</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SPGrid</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">page_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4096</span><span class="p">;</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">block_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">dim</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">8</span><span class="p">;</span>

<span class="w">    </span><span class="kt">uint64_t</span><span class="o">*</span><span class="w"> </span><span class="n">page_table</span><span class="p">;</span><span class="w">  </span><span class="c1">// 页表跟踪</span>
<span class="w">    </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">;</span><span class="w">               </span><span class="c1">// 虚拟内存池</span>

<span class="w">    </span><span class="kt">size_t</span><span class="w"> </span><span class="nf">offset</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Vec</span><span class="o">&lt;</span><span class="n">dim</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">idx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// Morton编码保持空间局部性</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">morton_encode</span><span class="p">(</span><span class="n">idx</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>OpenVDB特点</strong>：</p>
<ul>
<li>层次化B+树结构</li>
<li>支持极度稀疏数据</li>
<li>工业标准（电影特效）</li>
</ul>
<p><strong>树结构</strong>：</p>
<div class="codehilite"><pre><span></span><code>Root (dynamic hash map)
  └── Internal Node (32³ or 16³)
       └── Internal Node (16³ or 8³)  
            └── Leaf Node (8³)
</code></pre></div>

<h3 id="962">9.6.2 分层稀疏网格</h3>
<p>多分辨率表示的优势：</p>
<p><strong>自适应细化</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">HierarchicalGrid</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">Node</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">union</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">Node</span><span class="o">*</span><span class="w"> </span><span class="n">children</span><span class="p">[</span><span class="mi">8</span><span class="p">];</span><span class="w">  </span><span class="c1">// 内部节点</span>
<span class="w">            </span><span class="n">T</span><span class="w"> </span><span class="n">data</span><span class="p">[</span><span class="mi">8</span><span class="o">*</span><span class="mi">8</span><span class="o">*</span><span class="mi">8</span><span class="p">];</span><span class="w">      </span><span class="c1">// 叶子节点</span>
<span class="w">        </span><span class="p">};</span>
<span class="w">        </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">mask</span><span class="p">;</span><span class="w">           </span><span class="c1">// 子节点存在性</span>

<span class="w">        </span><span class="kt">bool</span><span class="w"> </span><span class="nf">is_leaf</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">mask</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x80</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="p">};</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">refine</span><span class="p">(</span><span class="n">Node</span><span class="o">*</span><span class="w"> </span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="n">Vec3</span><span class="o">&amp;</span><span class="w"> </span><span class="n">pos</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">need_refinement</span><span class="p">(</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">pos</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">split_node</span><span class="p">(</span><span class="n">node</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>内存池管理</strong>：</p>
<ul>
<li>预分配大块内存</li>
<li>自定义分配器减少碎片</li>
<li>延迟释放提高重用率</li>
</ul>
<h3 id="963">9.6.3 位掩码与指针结构</h3>
<p><strong>位掩码优化</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">SparseMask</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">mask</span><span class="p">[</span><span class="n">BLOCKS</span><span class="o">/</span><span class="mi">64</span><span class="p">];</span><span class="w">  </span><span class="c1">// 每bit表示一个block</span>

<span class="w">    </span><span class="kt">bool</span><span class="w"> </span><span class="nf">is_active</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">mask</span><span class="p">[</span><span class="n">idx</span><span class="o">/</span><span class="mi">64</span><span class="p">]</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="p">(</span><span class="mi">1ULL</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="o">%</span><span class="mi">64</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">activate</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">mask</span><span class="p">[</span><span class="n">idx</span><span class="o">/</span><span class="mi">64</span><span class="p">]</span><span class="w"> </span><span class="o">|=</span><span class="w"> </span><span class="p">(</span><span class="mi">1ULL</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="o">%</span><span class="mi">64</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="nf">popcount</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w">  </span><span class="c1">// 活跃block数</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">mask</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">count</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">__builtin_popcountll</span><span class="p">(</span><span class="n">m</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">count</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>指针压缩</strong>：</p>
<ul>
<li>使用相对偏移代替绝对地址</li>
<li>32位索引处理大部分情况</li>
<li>指针打包提高缓存效率</li>
</ul>
<h3 id="964">9.6.4 动态拓扑更新</h3>
<p><strong>增量更新策略</strong>：</p>
<ol>
<li><strong>延迟分配</strong>：首次写入时分配</li>
<li><strong>批量更新</strong>：累积修改减少开销</li>
<li><strong>垃圾回收</strong>：定期清理空块</li>
</ol>
<p><strong>并发更新</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ConcurrentSparseGrid</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">Block</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">atomic</span><span class="o">&lt;</span><span class="kt">uint32_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">version</span><span class="p">;</span>
<span class="w">        </span><span class="n">T</span><span class="w"> </span><span class="n">data</span><span class="p">[</span><span class="n">BLOCK_SIZE</span><span class="p">];</span>
<span class="w">    </span><span class="p">};</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Vec3</span><span class="o">&amp;</span><span class="w"> </span><span class="n">pos</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">Block</span><span class="o">*</span><span class="w"> </span><span class="n">block</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_or_create_block</span><span class="p">(</span><span class="n">pos</span><span class="p">);</span>
<span class="w">        </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">ver</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">block</span><span class="o">-&gt;</span><span class="n">version</span><span class="p">.</span><span class="n">load</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// 乐观并发控制</span>
<span class="w">        </span><span class="n">block</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">[</span><span class="n">local_idx</span><span class="p">(</span><span class="n">pos</span><span class="p">)]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">value</span><span class="p">;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">block</span><span class="o">-&gt;</span><span class="n">version</span><span class="p">.</span><span class="n">compare_exchange_weak</span><span class="p">(</span><span class="n">ver</span><span class="p">,</span><span class="w"> </span><span class="n">ver</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// 重试或使用其他策略</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<h2 id="97">9.7 算法优化技术</h2>
<h3 id="971">9.7.1 循环优化</h3>
<p>循环是数值计算的核心，优化循环对性能至关重要：</p>
<p><strong>循环展开(Loop Unrolling)</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 原始循环</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>

<span class="c1">// 4倍展开</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="mi">-3</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">           </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">3</span><span class="p">];</span>
<span class="p">}</span>
<span class="c1">// 处理剩余元素</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">n</span><span class="o">%</span><span class="mi">4</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>循环阻塞(Loop Blocking/Tiling)</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 矩阵乘法的缓存优化版本</span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">TILE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">64</span><span class="p">;</span><span class="w">  </span><span class="c1">// 选择适合L1缓存的块大小</span>

<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">ii</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">ii</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">ii</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">TILE</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">jj</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">jj</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">jj</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">TILE</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">kk</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">kk</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">kk</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">TILE</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// 处理一个TILE×TILE的块</span>
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ii</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="n">ii</span><span class="o">+</span><span class="n">TILE</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">jj</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="n">jj</span><span class="o">+</span><span class="n">TILE</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="kt">double</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
<span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">kk</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="n">kk</span><span class="o">+</span><span class="n">TILE</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span><span class="w"> </span><span class="n">k</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                        </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
<span class="w">                    </span><span class="p">}</span>
<span class="w">                    </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>循环融合(Loop Fusion)</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 分离的循环</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">e</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>

<span class="c1">// 融合后：减少内存流量</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="n">d</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">e</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w">  </span><span class="c1">// a[i]还在缓存中</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>循环交换(Loop Interchange)</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 原始：列优先访问（缓存不友好）</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">process</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 交换后：行优先访问（缓存友好）</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">process</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="972">9.7.2 数据重排与预取</h3>
<p><strong>AoS到SoA转换</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// Array of Structures (AoS) - 缓存不友好</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">Particle_AoS</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">vx</span><span class="p">,</span><span class="w"> </span><span class="n">vy</span><span class="p">,</span><span class="w"> </span><span class="n">vz</span><span class="p">;</span>
<span class="p">};</span>
<span class="n">Particle_AoS</span><span class="w"> </span><span class="n">particles</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>

<span class="c1">// Structure of Arrays (SoA) - SIMD友好</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">Particles_SoA</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="n">N</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">N</span><span class="p">],</span><span class="w"> </span><span class="n">z</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">vx</span><span class="p">[</span><span class="n">N</span><span class="p">],</span><span class="w"> </span><span class="n">vy</span><span class="p">[</span><span class="n">N</span><span class="p">],</span><span class="w"> </span><span class="n">vz</span><span class="p">[</span><span class="n">N</span><span class="p">];</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>软件预取</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="nf">process_with_prefetch</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">PREFETCH_DISTANCE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span><span class="p">;</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 预取未来的数据</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">PREFETCH_DISTANCE</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">__builtin_prefetch</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">PREFETCH_DISTANCE</span><span class="p">],</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// 处理当前数据</span>
<span class="w">        </span><span class="n">expensive_computation</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>数据打包优化</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 压缩存储减少内存带宽</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">CompressedParticle</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 位置使用相对坐标（16位整数）</span>
<span class="w">    </span><span class="kt">int16_t</span><span class="w"> </span><span class="n">dx</span><span class="p">,</span><span class="w"> </span><span class="n">dy</span><span class="p">,</span><span class="w"> </span><span class="n">dz</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// 速度使用半精度浮点</span>
<span class="w">    </span><span class="n">half</span><span class="w"> </span><span class="n">vx</span><span class="p">,</span><span class="w"> </span><span class="n">vy</span><span class="p">,</span><span class="w"> </span><span class="n">vz</span><span class="p">;</span>
<span class="p">};</span>

<span class="c1">// 解压时转换回全精度</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">decompress</span><span class="p">(</span><span class="n">CompressedParticle</span><span class="o">&amp;</span><span class="w"> </span><span class="n">cp</span><span class="p">,</span><span class="w"> </span><span class="n">Particle</span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="n">Vec3</span><span class="w"> </span><span class="n">base</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">p</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">base</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cp</span><span class="p">.</span><span class="n">dx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">SCALE</span><span class="p">;</span>
<span class="w">    </span><span class="n">p</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">base</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cp</span><span class="p">.</span><span class="n">dy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">SCALE</span><span class="p">;</span>
<span class="w">    </span><span class="n">p</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">base</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cp</span><span class="p">.</span><span class="n">dz</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">SCALE</span><span class="p">;</span>
<span class="w">    </span><span class="n">p</span><span class="p">.</span><span class="n">vx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">float</span><span class="p">(</span><span class="n">cp</span><span class="p">.</span><span class="n">vx</span><span class="p">);</span>
<span class="w">    </span><span class="n">p</span><span class="p">.</span><span class="n">vy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">float</span><span class="p">(</span><span class="n">cp</span><span class="p">.</span><span class="n">vy</span><span class="p">);</span>
<span class="w">    </span><span class="n">p</span><span class="p">.</span><span class="n">vz</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">float</span><span class="p">(</span><span class="n">cp</span><span class="p">.</span><span class="n">vz</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="973">9.7.3 向量化技巧</h3>
<p><strong>手动向量化with Intrinsics</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 标量版本</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">add_scalar</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// AVX向量化版本</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">add_avx</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="c1">// 主循环：8个元素一组</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">7</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">__m256</span><span class="w"> </span><span class="n">va</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_mm256_load_ps</span><span class="p">(</span><span class="o">&amp;</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">        </span><span class="n">__m256</span><span class="w"> </span><span class="n">vb</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_mm256_load_ps</span><span class="p">(</span><span class="o">&amp;</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">        </span><span class="n">__m256</span><span class="w"> </span><span class="n">vc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_mm256_add_ps</span><span class="p">(</span><span class="n">va</span><span class="p">,</span><span class="w"> </span><span class="n">vb</span><span class="p">);</span>
<span class="w">        </span><span class="n">_mm256_store_ps</span><span class="p">(</span><span class="o">&amp;</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">vc</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// 处理剩余元素</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>数据对齐</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 确保32字节对齐（AVX需要）</span>
<span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="nf">aligned_alloc_float</span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">posix_memalign</span><span class="p">(</span><span class="o">&amp;</span><span class="n">ptr</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">))</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// 使用aligned属性</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">alignas</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="n">AlignedData</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">values</span><span class="p">[</span><span class="mi">8</span><span class="p">];</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>避免Gather/Scatter</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// Bad: gather操作性能差</span>
<span class="n">__m256</span><span class="w"> </span><span class="nf">gather_bad</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">indices</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">_mm256_i32gather_ps</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">_mm256_load_si256</span><span class="p">((</span><span class="n">__m256i</span><span class="o">*</span><span class="p">)</span><span class="n">indices</span><span class="p">),</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// Good: 重组数据避免gather</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">transpose_block_8x8</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">__m256</span><span class="w"> </span><span class="n">row0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_mm256_load_ps</span><span class="p">(</span><span class="n">src</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">0</span><span class="o">*</span><span class="n">stride</span><span class="p">);</span>
<span class="w">    </span><span class="n">__m256</span><span class="w"> </span><span class="n">row1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">_mm256_load_ps</span><span class="p">(</span><span class="n">src</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="o">*</span><span class="n">stride</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// ... 加载所有行</span>

<span class="w">    </span><span class="c1">// 使用shuffle和blend进行转置</span>
<span class="w">    </span><span class="c1">// ... 转置操作</span>

<span class="w">    </span><span class="n">_mm256_store_ps</span><span class="p">(</span><span class="n">dst</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">0</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="n">col0</span><span class="p">);</span>
<span class="w">    </span><span class="n">_mm256_store_ps</span><span class="p">(</span><span class="n">dst</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="n">col1</span><span class="p">);</span>
<span class="w">    </span><span class="c1">// ... 存储所有列</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="974">9.7.4 通信隐藏</h3>
<p><strong>计算与通信重叠</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// MPI非阻塞通信示例</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">overlap_compute_comm</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">local_data</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">halo_data</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">MPI_Request</span><span class="w"> </span><span class="n">requests</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// 启动非阻塞接收</span>
<span class="w">    </span><span class="n">MPI_Irecv</span><span class="p">(</span><span class="n">halo_left</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_FLOAT</span><span class="p">,</span><span class="w"> </span><span class="n">left_rank</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span>
<span class="w">              </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">requests</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">    </span><span class="n">MPI_Irecv</span><span class="p">(</span><span class="n">halo_right</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_FLOAT</span><span class="p">,</span><span class="w"> </span><span class="n">right_rank</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span>
<span class="w">              </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">requests</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>

<span class="w">    </span><span class="c1">// 启动非阻塞发送</span>
<span class="w">    </span><span class="n">MPI_Isend</span><span class="p">(</span><span class="n">send_left</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_FLOAT</span><span class="p">,</span><span class="w"> </span><span class="n">left_rank</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span>
<span class="w">              </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">requests</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
<span class="w">    </span><span class="n">MPI_Isend</span><span class="p">(</span><span class="n">send_right</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_FLOAT</span><span class="p">,</span><span class="w"> </span><span class="n">right_rank</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span>
<span class="w">              </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">requests</span><span class="p">[</span><span class="mi">3</span><span class="p">]);</span>

<span class="w">    </span><span class="c1">// 计算内部区域（不依赖halo）</span>
<span class="w">    </span><span class="n">compute_interior</span><span class="p">(</span><span class="n">local_data</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 等待通信完成</span>
<span class="w">    </span><span class="n">MPI_Waitall</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="n">requests</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_STATUSES_IGNORE</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 计算边界区域（使用halo数据）</span>
<span class="w">    </span><span class="n">compute_boundary</span><span class="p">(</span><span class="n">local_data</span><span class="p">,</span><span class="w"> </span><span class="n">halo_left</span><span class="p">,</span><span class="w"> </span><span class="n">halo_right</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>双缓冲Pipeline</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<span class="k">class</span><span class="w"> </span><span class="nc">DoubleBuffer</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">buffers</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">current</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="k">public</span><span class="o">:</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="n">swap</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">current</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">current</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">read_buffer</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">buffers</span><span class="p">[</span><span class="n">current</span><span class="p">];</span><span class="w"> </span><span class="p">}</span>
<span class="w">    </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">write_buffer</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">buffers</span><span class="p">[</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">current</span><span class="p">];</span><span class="w"> </span><span class="p">}</span>
<span class="p">};</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">pipeline_processing</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">DoubleBuffer</span><span class="o">&lt;</span><span class="n">Data</span><span class="o">&gt;</span><span class="w"> </span><span class="n">buffer</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 启动第一次读取</span>
<span class="w">    </span><span class="n">async_read</span><span class="p">(</span><span class="n">buffer</span><span class="p">.</span><span class="n">write_buffer</span><span class="p">());</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">iterations</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">buffer</span><span class="p">.</span><span class="n">swap</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// 并行：处理当前数据 + 读取下一批</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">future</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">async</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">launch</span><span class="o">::</span><span class="n">async</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="o">&amp;</span><span class="p">]()</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">async_read</span><span class="p">(</span><span class="n">buffer</span><span class="p">.</span><span class="n">write_buffer</span><span class="p">());</span>
<span class="w">        </span><span class="p">});</span>

<span class="w">        </span><span class="n">process</span><span class="p">(</span><span class="n">buffer</span><span class="p">.</span><span class="n">read_buffer</span><span class="p">());</span>

<span class="w">        </span><span class="n">future</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>GPU异步传输</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="nf">multi_stream_processing</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">h_data</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_data</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">chunks</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">chunks</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">streams</span><span class="p">[</span><span class="n">chunks</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// 创建流</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">chunks</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 异步处理</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">chunks</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">chunk_size</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 异步拷贝到GPU</span>
<span class="w">        </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">d_data</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="n">h_data</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span>
<span class="w">                       </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span>
<span class="w">                       </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span><span class="w"> </span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>

<span class="w">        </span><span class="c1">// 在流中启动kernel</span>
<span class="w">        </span><span class="n">process_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threads</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&gt;&gt;&gt;</span>
<span class="w">                      </span><span class="p">(</span><span class="n">d_data</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="n">chunk_size</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 异步拷贝回CPU</span>
<span class="w">        </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">h_data</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span><span class="n">d_data</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">,</span><span class="w"> </span>
<span class="w">                       </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span>
<span class="w">                       </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">,</span><span class="w"> </span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 同步所有流</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">chunks</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">        </span><span class="n">cudaStreamDestroy</span><span class="p">(</span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h2 id="98-gpu">9.8 多GPU并行</h2>
<h3 id="981">9.8.1 域分解策略</h3>
<p><strong>1D分解</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">Domain1D</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">global_size</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">gpu_id</span><span class="p">;</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="nf">local_size</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">global_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">num_gpus</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="nf">local_start</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">gpu_id</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">local_size</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="nf">local_end</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="n">local_start</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">local_size</span><span class="p">(),</span><span class="w"> </span><span class="n">global_size</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>2D/3D分解</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">Domain3D</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">int3</span><span class="w"> </span><span class="n">global_size</span><span class="p">;</span>
<span class="w">    </span><span class="n">int3</span><span class="w"> </span><span class="n">gpu_grid</span><span class="p">;</span><span class="w">    </span><span class="c1">// GPU的3D排列</span>
<span class="w">    </span><span class="n">int3</span><span class="w"> </span><span class="n">gpu_coords</span><span class="p">;</span><span class="w">  </span><span class="c1">// 当前GPU的坐标</span>

<span class="w">    </span><span class="n">int3</span><span class="w"> </span><span class="nf">local_size</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">make_int3</span><span class="p">(</span>
<span class="w">            </span><span class="p">(</span><span class="n">global_size</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpu_grid</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">gpu_grid</span><span class="p">.</span><span class="n">x</span><span class="p">,</span>
<span class="w">            </span><span class="p">(</span><span class="n">global_size</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpu_grid</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">gpu_grid</span><span class="p">.</span><span class="n">y</span><span class="p">,</span>
<span class="w">            </span><span class="p">(</span><span class="n">global_size</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">gpu_grid</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">gpu_grid</span><span class="p">.</span><span class="n">z</span>
<span class="w">        </span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 计算表面积/体积比</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="nf">surface_volume_ratio</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">int3</span><span class="w"> </span><span class="n">ls</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">local_size</span><span class="p">();</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">surface</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">ls</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">ls</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ls</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">ls</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ls</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">ls</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">volume</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ls</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">ls</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">ls</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="kt">float</span><span class="p">(</span><span class="n">surface</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">volume</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>最优分解选择</strong>：</p>
<ul>
<li>最小化通信量：减小表面积/体积比</li>
<li>考虑问题的各向异性</li>
<li>匹配硬件拓扑（如NVLink连接）</li>
</ul>
<h3 id="982-halo">9.8.2 Halo区域交换</h3>
<p><strong>Ghost Cell实现</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">HaloExchange</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">int3</span><span class="w"> </span><span class="n">local_size</span><span class="p">;</span>
<span class="w">    </span><span class="n">int3</span><span class="w"> </span><span class="n">halo_width</span><span class="p">;</span>
<span class="w">    </span><span class="n">int3</span><span class="w"> </span><span class="n">total_size</span><span class="p">;</span><span class="w">  </span><span class="c1">// local + 2*halo</span>

<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 6个方向的邻居GPU</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">neighbors</span><span class="p">[</span><span class="mi">6</span><span class="p">];</span><span class="w">  </span><span class="c1">// -x, +x, -y, +y, -z, +z</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">exchange_halos</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// X方向交换</span>
<span class="w">        </span><span class="n">exchange_x_direction</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// Y方向交换（包含X方向的halo）</span>
<span class="w">        </span><span class="n">exchange_y_direction</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// Z方向交换（包含X,Y方向的halo）</span>
<span class="w">        </span><span class="n">exchange_z_direction</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">exchange_x_direction</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">size_t</span><span class="w"> </span><span class="n">yz_slice_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">halo_width</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">local_size</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">local_size</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 准备发送缓冲区</span>
<span class="w">        </span><span class="n">pack_x_minus</span><span class="p">(</span><span class="n">send_buffer_xm</span><span class="p">);</span>
<span class="w">        </span><span class="n">pack_x_plus</span><span class="p">(</span><span class="n">send_buffer_xp</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 非阻塞P2P传输</span>
<span class="w">        </span><span class="n">cudaMemcpyPeerAsync</span><span class="p">(</span><span class="n">recv_xm</span><span class="p">,</span><span class="w"> </span><span class="n">gpu_xm</span><span class="p">,</span><span class="w"> </span><span class="n">send_xp</span><span class="p">,</span><span class="w"> </span><span class="n">gpu_id</span><span class="p">,</span><span class="w"> </span>
<span class="w">                           </span><span class="n">yz_slice_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">stream_xm</span><span class="p">);</span>
<span class="w">        </span><span class="n">cudaMemcpyPeerAsync</span><span class="p">(</span><span class="n">recv_xp</span><span class="p">,</span><span class="w"> </span><span class="n">gpu_xp</span><span class="p">,</span><span class="w"> </span><span class="n">send_xm</span><span class="p">,</span><span class="w"> </span><span class="n">gpu_id</span><span class="p">,</span><span class="w"> </span>
<span class="w">                           </span><span class="n">yz_slice_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">stream_xp</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 同步</span>
<span class="w">        </span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">stream_xm</span><span class="p">);</span>
<span class="w">        </span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">stream_xp</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 解包到halo区域</span>
<span class="w">        </span><span class="n">unpack_x_minus</span><span class="p">(</span><span class="n">recv_buffer_xm</span><span class="p">);</span>
<span class="w">        </span><span class="n">unpack_x_plus</span><span class="p">(</span><span class="n">recv_buffer_xp</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>GPUDirect P2P优化</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="nf">enable_peer_access</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="kt">int</span><span class="w"> </span><span class="n">can_access</span><span class="p">;</span>
<span class="w">                </span><span class="n">cudaDeviceCanAccessPeer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">can_access</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">j</span><span class="p">);</span>
<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">can_access</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="n">cudaDeviceEnablePeerAccess</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>重叠计算和通信</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="nf">timestep_with_overlap</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 1. 启动halo交换（非阻塞）</span>
<span class="w">    </span><span class="n">start_halo_exchange</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// 2. 计算内部区域（不需要halo）</span>
<span class="w">    </span><span class="n">dim3</span><span class="w"> </span><span class="n">interior_blocks</span><span class="p">(</span>
<span class="w">        </span><span class="p">(</span><span class="n">local_size</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">halo_width</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">255</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span>
<span class="w">        </span><span class="n">local_size</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">halo_width</span><span class="p">.</span><span class="n">y</span><span class="p">,</span>
<span class="w">        </span><span class="n">local_size</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">halo_width</span><span class="p">.</span><span class="n">z</span>
<span class="w">    </span><span class="p">);</span>
<span class="w">    </span><span class="n">compute_interior</span><span class="o">&lt;&lt;&lt;</span><span class="n">interior_blocks</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">compute_stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span>
<span class="w">        </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">local_size</span><span class="p">,</span><span class="w"> </span><span class="n">halo_width</span>
<span class="w">    </span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 3. 等待halo交换完成</span>
<span class="w">    </span><span class="n">finish_halo_exchange</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// 4. 计算边界区域</span>
<span class="w">    </span><span class="n">compute_boundary_x</span><span class="o">&lt;&lt;&lt;</span><span class="p">...</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
<span class="w">    </span><span class="n">compute_boundary_y</span><span class="o">&lt;&lt;&lt;</span><span class="p">...</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
<span class="w">    </span><span class="n">compute_boundary_z</span><span class="o">&lt;&lt;&lt;</span><span class="p">...</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// 5. 同步所有计算</span>
<span class="w">    </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="983">9.8.3 异步传输与计算重叠</h3>
<p><strong>CUDA流管理</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">MultiGPUManager</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">GPUContext</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">device_id</span><span class="p">;</span>
<span class="w">        </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">compute_stream</span><span class="p">;</span>
<span class="w">        </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">transfer_stream</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span><span class="w">  </span><span class="c1">// 双缓冲传输</span>

<span class="w">        </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_data</span><span class="p">;</span><span class="w">      </span><span class="c1">// 设备内存</span>
<span class="w">        </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">h_buffer</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span><span class="w"> </span><span class="c1">// 钉扎内存缓冲区</span>
<span class="w">    </span><span class="p">};</span>

<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">GPUContext</span><span class="o">&gt;</span><span class="w"> </span><span class="n">contexts</span><span class="p">;</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">process_multi_gpu</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 为每个GPU创建上下文</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="w">            </span><span class="n">contexts</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">compute_stream</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_stream</span><span class="p">();</span>
<span class="w">            </span><span class="n">contexts</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">transfer_stream</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_stream</span><span class="p">();</span>
<span class="w">            </span><span class="n">contexts</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">transfer_stream</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_stream</span><span class="p">();</span>

<span class="w">            </span><span class="c1">// 分配钉扎内存加速传输</span>
<span class="w">            </span><span class="n">cudaHostAlloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">contexts</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">h_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">buffer_size</span><span class="p">,</span><span class="w"> </span>
<span class="w">                         </span><span class="n">cudaHostAllocPortable</span><span class="p">);</span>
<span class="w">            </span><span class="n">cudaHostAlloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">contexts</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">h_buffer</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">buffer_size</span><span class="p">,</span><span class="w"> </span>
<span class="w">                         </span><span class="n">cudaHostAllocPortable</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// Pipeline处理</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_iterations</span><span class="p">;</span><span class="w"> </span><span class="n">iter</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">gpu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">gpu</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">gpu</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">gpu</span><span class="p">);</span>
<span class="w">                </span><span class="k">auto</span><span class="o">&amp;</span><span class="w"> </span><span class="n">ctx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">contexts</span><span class="p">[</span><span class="n">gpu</span><span class="p">];</span>

<span class="w">                </span><span class="kt">int</span><span class="w"> </span><span class="n">buf_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>

<span class="w">                </span><span class="c1">// 异步传输下一批数据</span>
<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">iter</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_iterations</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="n">prepare_next_data</span><span class="p">(</span><span class="n">ctx</span><span class="p">.</span><span class="n">h_buffer</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="n">buf_idx</span><span class="p">],</span><span class="w"> </span><span class="n">iter</span><span class="o">+</span><span class="mi">1</span><span class="p">);</span>
<span class="w">                    </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">ctx</span><span class="p">.</span><span class="n">d_data</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">.</span><span class="n">h_buffer</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="n">buf_idx</span><span class="p">],</span>
<span class="w">                                   </span><span class="n">data_size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span>
<span class="w">                                   </span><span class="n">ctx</span><span class="p">.</span><span class="n">transfer_stream</span><span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="n">buf_idx</span><span class="p">]);</span>
<span class="w">                </span><span class="p">}</span>

<span class="w">                </span><span class="c1">// 在当前数据上计算</span>
<span class="w">                </span><span class="n">compute_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">ctx</span><span class="p">.</span><span class="n">compute_stream</span><span class="o">&gt;&gt;&gt;</span>
<span class="w">                              </span><span class="p">(</span><span class="n">ctx</span><span class="p">.</span><span class="n">d_data</span><span class="p">,</span><span class="w"> </span><span class="n">params</span><span class="p">);</span>

<span class="w">                </span><span class="c1">// 等待上一次传输完成</span>
<span class="w">                </span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">ctx</span><span class="p">.</span><span class="n">transfer_stream</span><span class="p">[</span><span class="n">buf_idx</span><span class="p">]);</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>事件同步</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">EventSync</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaEvent_t</span><span class="w"> </span><span class="n">events</span><span class="p">[</span><span class="n">MAX_GPUS</span><span class="p">][</span><span class="n">MAX_EVENTS</span><span class="p">];</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">cross_gpu_dependency</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// GPU 0完成计算</span>
<span class="w">        </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="w">        </span><span class="n">kernel_gpu0</span><span class="o">&lt;&lt;&lt;</span><span class="p">...</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
<span class="w">        </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">events</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]);</span>

<span class="w">        </span><span class="c1">// GPU 1等待GPU 0</span>
<span class="w">        </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">        </span><span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream_gpu1</span><span class="p">,</span><span class="w"> </span><span class="n">events</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">        </span><span class="n">kernel_gpu1</span><span class="o">&lt;&lt;&lt;</span><span class="p">...,</span><span class="w"> </span><span class="n">stream_gpu1</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// 可以形成复杂的依赖DAG</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<h3 id="984">9.8.4 负载动态迁移</h3>
<p><strong>工作窃取实现</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">WorkStealingScheduler</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">WorkQueue</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">atomic</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">head</span><span class="p">;</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">atomic</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">tail</span><span class="p">;</span>
<span class="w">        </span><span class="n">Task</span><span class="o">*</span><span class="w"> </span><span class="n">tasks</span><span class="p">[</span><span class="n">QUEUE_SIZE</span><span class="p">];</span>

<span class="w">        </span><span class="kt">bool</span><span class="w"> </span><span class="nf">try_push</span><span class="p">(</span><span class="n">Task</span><span class="o">*</span><span class="w"> </span><span class="n">task</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">head</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">memory_order_acquire</span><span class="p">);</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tail</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">memory_order_relaxed</span><span class="p">);</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">t</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">QUEUE_SIZE</span><span class="p">)</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>

<span class="w">            </span><span class="n">tasks</span><span class="p">[</span><span class="n">t</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">QUEUE_SIZE</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">task</span><span class="p">;</span>
<span class="w">            </span><span class="n">tail</span><span class="p">.</span><span class="n">store</span><span class="p">(</span><span class="n">t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">memory_order_release</span><span class="p">);</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="n">Task</span><span class="o">*</span><span class="w"> </span><span class="nf">try_pop</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">head</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">memory_order_relaxed</span><span class="p">);</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tail</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">memory_order_acquire</span><span class="p">);</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">h</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">t</span><span class="p">)</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>

<span class="w">            </span><span class="n">Task</span><span class="o">*</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tasks</span><span class="p">[</span><span class="n">h</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">QUEUE_SIZE</span><span class="p">];</span>
<span class="w">            </span><span class="n">head</span><span class="p">.</span><span class="n">store</span><span class="p">(</span><span class="n">h</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">memory_order_release</span><span class="p">);</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">task</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="n">Task</span><span class="o">*</span><span class="w"> </span><span class="nf">try_steal</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">h</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">head</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">memory_order_acquire</span><span class="p">);</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tail</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">memory_order_acquire</span><span class="p">);</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">h</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">t</span><span class="p">)</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>

<span class="w">            </span><span class="n">Task</span><span class="o">*</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tasks</span><span class="p">[</span><span class="n">h</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">QUEUE_SIZE</span><span class="p">];</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">head</span><span class="p">.</span><span class="n">compare_exchange_strong</span><span class="p">(</span><span class="n">h</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="n">task</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="k">nullptr</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">};</span>

<span class="w">    </span><span class="n">WorkQueue</span><span class="w"> </span><span class="n">queues</span><span class="p">[</span><span class="n">MAX_GPUS</span><span class="p">];</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">gpu_worker</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">gpu_id</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">gpu_id</span><span class="p">);</span>
<span class="w">        </span><span class="n">WorkQueue</span><span class="o">&amp;</span><span class="w"> </span><span class="n">my_queue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">queues</span><span class="p">[</span><span class="n">gpu_id</span><span class="p">];</span>

<span class="w">        </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">done</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">Task</span><span class="o">*</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">my_queue</span><span class="p">.</span><span class="n">try_pop</span><span class="p">();</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">task</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="c1">// 尝试从其他GPU窃取</span>
<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">victim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">victim</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">victim</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">victim</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="n">gpu_id</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                        </span><span class="n">task</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">queues</span><span class="p">[</span><span class="n">victim</span><span class="p">].</span><span class="n">try_steal</span><span class="p">();</span>
<span class="w">                        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">task</span><span class="p">)</span><span class="w"> </span><span class="k">break</span><span class="p">;</span>
<span class="w">                    </span><span class="p">}</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">task</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">execute_task</span><span class="p">(</span><span class="n">task</span><span class="p">,</span><span class="w"> </span><span class="n">gpu_id</span><span class="p">);</span>
<span class="w">            </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">yield</span><span class="p">();</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>动态负载监控</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">LoadMonitor</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">GPULoad</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">atomic</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">utilization</span><span class="p">;</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">atomic</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">task_count</span><span class="p">;</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">atomic</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">total_time</span><span class="p">;</span>
<span class="w">    </span><span class="p">};</span>

<span class="w">    </span><span class="n">GPULoad</span><span class="w"> </span><span class="n">loads</span><span class="p">[</span><span class="n">MAX_GPUS</span><span class="p">];</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">update_load</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">gpu_id</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">util</span><span class="p">,</span><span class="w"> </span><span class="kt">int64_t</span><span class="w"> </span><span class="n">task_time</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">loads</span><span class="p">[</span><span class="n">gpu_id</span><span class="p">].</span><span class="n">utilization</span><span class="p">.</span><span class="n">store</span><span class="p">(</span><span class="n">util</span><span class="p">);</span>
<span class="w">        </span><span class="n">loads</span><span class="p">[</span><span class="n">gpu_id</span><span class="p">].</span><span class="n">task_count</span><span class="p">.</span><span class="n">fetch_add</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">        </span><span class="n">loads</span><span class="p">[</span><span class="n">gpu_id</span><span class="p">].</span><span class="n">total_time</span><span class="p">.</span><span class="n">fetch_add</span><span class="p">(</span><span class="n">task_time</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="nf">find_least_loaded_gpu</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">min_load</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">best_gpu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">load</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loads</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">utilization</span><span class="p">.</span><span class="n">load</span><span class="p">();</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">load</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">min_load</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">min_load</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">load</span><span class="p">;</span>
<span class="w">                </span><span class="n">best_gpu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">best_gpu</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">rebalance_work</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 计算平均负载</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">avg_load</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">avg_load</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">loads</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">utilization</span><span class="p">.</span><span class="n">load</span><span class="p">();</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="n">avg_load</span><span class="w"> </span><span class="o">/=</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 识别过载和空闲GPU</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">overloaded</span><span class="p">,</span><span class="w"> </span><span class="n">underloaded</span><span class="p">;</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">load</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">loads</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">utilization</span><span class="p">.</span><span class="n">load</span><span class="p">();</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">load</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">avg_load</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.2f</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">overloaded</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="w">            </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">load</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">avg_load</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">0.8f</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">underloaded</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// 迁移任务</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">src</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">overloaded</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">dst</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">underloaded</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">migrate_tasks</span><span class="p">(</span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">dst</span><span class="p">);</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>NCCL集合通信</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="nf">nccl_allreduce_example</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">ncclComm_t</span><span class="w"> </span><span class="n">comms</span><span class="p">[</span><span class="n">num_gpus</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// 初始化NCCL</span>
<span class="w">    </span><span class="n">ncclCommInitAll</span><span class="p">(</span><span class="n">comms</span><span class="p">,</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">,</span><span class="w"> </span><span class="n">device_ids</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 每个GPU执行allreduce</span>
<span class="w">    </span><span class="cp">#pragma omp parallel num_threads(num_gpus)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">gpu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">omp_get_thread_num</span><span class="p">();</span>
<span class="w">        </span><span class="n">cudaSetDevice</span><span class="p">(</span><span class="n">gpu</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 局部计算</span>
<span class="w">        </span><span class="n">compute_local</span><span class="o">&lt;&lt;&lt;</span><span class="p">...</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_data</span><span class="p">[</span><span class="n">gpu</span><span class="p">]);</span>

<span class="w">        </span><span class="c1">// 全局归约</span>
<span class="w">        </span><span class="n">ncclAllReduce</span><span class="p">(</span><span class="n">d_data</span><span class="p">[</span><span class="n">gpu</span><span class="p">],</span><span class="w"> </span><span class="n">d_data</span><span class="p">[</span><span class="n">gpu</span><span class="p">],</span><span class="w"> </span><span class="n">data_size</span><span class="p">,</span>
<span class="w">                     </span><span class="n">ncclFloat</span><span class="p">,</span><span class="w"> </span><span class="n">ncclSum</span><span class="p">,</span><span class="w"> </span><span class="n">comms</span><span class="p">[</span><span class="n">gpu</span><span class="p">],</span><span class="w"> </span>
<span class="w">                     </span><span class="n">streams</span><span class="p">[</span><span class="n">gpu</span><span class="p">]);</span>

<span class="w">        </span><span class="c1">// 等待完成</span>
<span class="w">        </span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">streams</span><span class="p">[</span><span class="n">gpu</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 清理</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">ncclCommDestroy</span><span class="p">(</span><span class="n">comms</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h2 id="_2">本章小结</h2>
<p>本章深入探讨了高性能计算在物理引擎中的应用，从底层硬件架构到高层算法优化：</p>
<ol>
<li>
<p><strong>处理器微架构</strong>：理解CPU流水线、SIMD指令集、分支预测和乱序执行对于编写高效代码至关重要。</p>
</li>
<li>
<p><strong>内存层级</strong>：缓存优化、NUMA感知编程和TLB优化能够显著提升内存密集型应用的性能。</p>
</li>
<li>
<p><strong>性能分析</strong>：Roofline模型帮助识别性能瓶颈，性能计数器和分析工具指导优化方向。</p>
</li>
<li>
<p><strong>并行编程模型</strong>：OpenMP简化共享内存并行，MPI支持分布式计算，合理的负载均衡策略确保高效率。</p>
</li>
<li>
<p><strong>GPU编程</strong>：理解GPU架构特点，优化内存访问模式和占用率，充分利用GPU的并行计算能力。</p>
</li>
<li>
<p><strong>稀疏数据结构</strong>：SPGrid和OpenVDB等技术处理大规模稀疏数据，动态拓扑更新支持自适应仿真。</p>
</li>
<li>
<p><strong>算法优化</strong>：循环优化、向量化、通信隐藏等技术在各个层面提升性能。</p>
</li>
<li>
<p><strong>多GPU并行</strong>：域分解、halo交换、异步传输和动态负载均衡实现可扩展的多GPU计算。</p>
</li>
</ol>
<h2 id="_3">练习题</h2>
<h3 id="_4">基础题</h3>
<ol>
<li><strong>缓存行分析</strong>
   给定以下代码，分析其缓存行为并优化：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">Particle</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">vx</span><span class="p">,</span><span class="w"> </span><span class="n">vy</span><span class="p">,</span><span class="w"> </span><span class="n">vz</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">mass</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="p">};</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">update_positions</span><span class="p">(</span><span class="n">Particle</span><span class="o">*</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">x</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">vx</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="p">;</span>
<span class="w">        </span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">y</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">vy</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="p">;</span>
<span class="w">        </span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">z</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">vz</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑AoS vs SoA布局，以及缓存行的利用率。
   </details>
<details markdown="block">
   <summary markdown="off">答案</summary>

   原始代码问题：

   - Particle结构体大小32字节，一个缓存行(64字节)只能容纳2个粒子
   - 更新位置时只使用了6/8的数据，缓存利用率75%

   优化方案1 - SoA布局：


<div class="codehilite"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">ParticlesSoA</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">;</span><span class="w">  </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">;</span><span class="w">  </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">z</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">vx</span><span class="p">;</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">vy</span><span class="p">;</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">vz</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">mass</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">type</span><span class="p">;</span>
<span class="p">};</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">update_positions_soa</span><span class="p">(</span><span class="n">ParticlesSoA</span><span class="o">&amp;</span><span class="w"> </span><span class="n">p</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">dt</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">p</span><span class="p">.</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">p</span><span class="p">.</span><span class="n">vx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="p">;</span>
<span class="w">        </span><span class="n">p</span><span class="p">.</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">p</span><span class="p">.</span><span class="n">vy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="p">;</span>
<span class="w">        </span><span class="n">p</span><span class="p">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">p</span><span class="p">.</span><span class="n">vz</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dt</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>



   优化方案2 - 数据分离：
   ```cpp
   struct Position { float x, y, z; };
   struct Velocity { float vx, vy, vz; };

   void update_positions_split(Position* pos, Velocity* vel, int n, float dt) {
       for (int i = 0; i &lt; n; i++) {
           pos[i].x += vel[i].vx * dt;
           pos[i].y += vel[i].vy * dt;
           pos[i].z += vel[i].vz * dt;
       }
   }
   ```
   </details>
<ol start="2">
<li><strong>Roofline模型应用</strong>
   某矩阵乘法核心循环执行2n³次浮点运算，读取2n²个浮点数。机器峰值性能1 TFLOPS，内存带宽100 GB/s。问：</li>
</ol>
<ul>
<li>a) 计算算术强度</li>
<li>b) n至少为多少时才能达到计算受限？</li>
<li>c) 如何通过分块提高性能？</li>
</ul>
<details markdown="block">
   <summary markdown="off">提示</summary>
   算术强度 = FLOPs / Bytes，机器平衡点 = Peak FLOPS / Bandwidth
   </details>
<details markdown="block">
   <summary markdown="off">答案</summary>

   a) 算术强度计算：

   - FLOPs = 2n³
   - Bytes = 2n² × 4 = 8n²（假设float）
   - AI = 2n³ / 8n² = n/4

   b) 机器平衡点：

   - Balance = 1000 GFLOPS / 100 GB/s = 10 FLOP/Byte
   - 需要 n/4 ≥ 10，即 n ≥ 40

   c) 分块优化：


<div class="codehilite"><pre><span></span><code><span class="c1">// 原始：AI = n/4</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
<span class="w">    </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>

<span class="c1">// 分块后：AI = TILE/4（每个块内）</span>
<span class="k">for</span><span class="p">(</span><span class="n">ii</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="p">(</span><span class="n">jj</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="p">(</span><span class="n">kk</span><span class="p">)</span><span class="w">  </span><span class="c1">// 块级循环</span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="p">(</span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="w">  </span><span class="c1">// 块内循环</span>
<span class="w">        </span><span class="n">C</span><span class="p">[</span><span class="n">ii</span><span class="o">+</span><span class="n">i</span><span class="p">][</span><span class="n">jj</span><span class="o">+</span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">ii</span><span class="o">+</span><span class="n">i</span><span class="p">][</span><span class="n">kk</span><span class="o">+</span><span class="n">k</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">kk</span><span class="o">+</span><span class="n">k</span><span class="p">][</span><span class="n">jj</span><span class="o">+</span><span class="n">j</span><span class="p">];</span>
</code></pre></div>


   选择TILE=64可以充分利用L1缓存，提高数据重用。
   </details>
<ol start="3">
<li><strong>GPU内存合并访问</strong>
   分析以下GPU kernel的内存访问模式：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">transpose</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">out</span><span class="p">[</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑warp内线程的访问模式，读和写的合并情况。
   </details>
<details markdown="block">
   <summary markdown="off">答案</summary>

   问题分析：

   - 读取：相邻线程读取跨步为n的元素，非合并访问
   - 写入：相邻线程写入连续地址，合并访问

   优化方案 - 使用共享内存：


<div class="codehilite"><pre><span></span><code><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">transpose_optimized</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="mi">32</span><span class="p">][</span><span class="mi">33</span><span class="p">];</span><span class="w">  </span><span class="c1">// +1避免bank冲突</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 合并读取到共享内存</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// 转置后的坐标</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 合并写入</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">out</span><span class="p">[</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>


   </details>
<ol start="4">
<li><strong>OpenMP负载均衡</strong>
   有一个粒子系统，每个粒子的计算成本与其邻居数成正比。如何用OpenMP实现动态负载均衡？</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   比较static、dynamic、guided调度策略的特点。
   </details>
<details markdown="block">
   <summary markdown="off">答案</summary>

   ```cpp
   // 方案1：动态调度
   #pragma omp parallel for schedule(dynamic, 16)
   for (int i = 0; i &lt; n_particles; i++) {
       int neighbors = count_neighbors(i);
       // 计算成本 ∝ neighbors
       compute_forces(i, neighbors);
   }

   // 方案2：预排序+静态调度
   // 先统计每个粒子的邻居数
   std::vector&lt;std::pair&lt;int, int&gt;&gt; workload;
   for (int i = 0; i &lt; n_particles; i++) {
       workload.push_back({count_neighbors(i), i});
   }

   // 按工作量排序，交错分配
   std::sort(workload.begin(), workload.end());

   #pragma omp parallel
   {
       int tid = omp_get_thread_num();
       int nthreads = omp_get_num_threads();

       // 循环分配确保负载均衡
       for (int i = tid; i &lt; n_particles; i += nthreads) {
           int particle_id = workload[i].second;
           compute_forces(particle_id, workload[i].first);
       }
   }

   // 方案3：任务并行
   #pragma omp parallel
   #pragma omp single
   {
       for (int i = 0; i &lt; n_particles; i++) {
           #pragma omp task
           {
               int neighbors = count_neighbors(i);
               compute_forces(i, neighbors);
           }
       }
   }
   ```
   </details>
<h3 id="_5">挑战题</h3>
<ol start="5">
<li><strong>多GPU域分解优化</strong>
   设计一个3D流体仿真的多GPU域分解方案，考虑：</li>
</ol>
<ul>
<li>最小化通信量</li>
<li>支持非均匀网格</li>
<li>动态负载均衡</li>
<li>容错性</li>
</ul>
<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑空间填充曲线、递归二分、图分割等方法。
   </details>
<details markdown="block">
   <summary markdown="off">答案</summary>

   综合方案设计：

   1. **初始分解** - 使用递归坐标二分(RCB)：


<div class="codehilite"><pre><span></span><code><span class="k">struct</span><span class="w"> </span><span class="nc">Domain</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">float3</span><span class="w"> </span><span class="n">min</span><span class="p">,</span><span class="w"> </span><span class="n">max</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">workload</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">gpu_id</span><span class="p">;</span>
<span class="p">};</span>

<span class="kt">void</span><span class="w"> </span><span class="nf">recursive_bisection</span><span class="p">(</span><span class="n">Domain</span><span class="o">&amp;</span><span class="w"> </span><span class="n">domain</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">level</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">gpu_start</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">gpu_count</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">gpu_count</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">domain</span><span class="p">.</span><span class="n">gpu_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gpu_start</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 选择最长维度切分</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">dim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">longest_dimension</span><span class="p">(</span><span class="n">domain</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 按工作量平衡找切分点</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">split</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">find_median_workload</span><span class="p">(</span><span class="n">domain</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 递归分解子域</span>
<span class="w">    </span><span class="n">Domain</span><span class="w"> </span><span class="n">left</span><span class="p">,</span><span class="w"> </span><span class="n">right</span><span class="p">;</span>
<span class="w">    </span><span class="n">split_domain</span><span class="p">(</span><span class="n">domain</span><span class="p">,</span><span class="w"> </span><span class="n">dim</span><span class="p">,</span><span class="w"> </span><span class="n">split</span><span class="p">,</span><span class="w"> </span><span class="n">left</span><span class="p">,</span><span class="w"> </span><span class="n">right</span><span class="p">);</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">left_gpus</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gpu_count</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="w">    </span><span class="n">recursive_bisection</span><span class="p">(</span><span class="n">left</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">gpu_start</span><span class="p">,</span><span class="w"> </span><span class="n">left_gpus</span><span class="p">);</span>
<span class="w">    </span><span class="n">recursive_bisection</span><span class="p">(</span><span class="n">right</span><span class="p">,</span><span class="w"> </span><span class="n">level</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">gpu_start</span><span class="o">+</span><span class="n">left_gpus</span><span class="p">,</span><span class="w"> </span><span class="n">gpu_count</span><span class="o">-</span><span class="n">left_gpus</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>



   2. **动态负载均衡** - 基于扩散的方法：


<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">LoadBalancer</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">GPUMetrics</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">computation_time</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">communication_time</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">particle_count</span><span class="p">;</span>
<span class="w">    </span><span class="p">};</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">rebalance</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 收集所有GPU的负载信息</span>
<span class="w">        </span><span class="n">GPUMetrics</span><span class="w"> </span><span class="n">metrics</span><span class="p">[</span><span class="n">num_gpus</span><span class="p">];</span>
<span class="w">        </span><span class="n">gather_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 计算平均负载</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">avg_time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compute_average_time</span><span class="p">(</span><span class="n">metrics</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 扩散算法：邻居间迁移粒子</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">iter</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">max_iterations</span><span class="p">;</span><span class="w"> </span><span class="n">iter</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">bool</span><span class="w"> </span><span class="n">converged</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">gpu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">gpu</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">;</span><span class="w"> </span><span class="n">gpu</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="n">gpu</span><span class="p">].</span><span class="n">computation_time</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">avg_time</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1.1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="c1">// 找到最空闲的邻居</span>
<span class="w">                    </span><span class="kt">int</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">find_least_loaded_neighbor</span><span class="p">(</span><span class="n">gpu</span><span class="p">);</span>

<span class="w">                    </span><span class="c1">// 计算迁移量</span>
<span class="w">                    </span><span class="kt">int</span><span class="w"> </span><span class="n">migrate_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">estimate_migration</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">metrics</span><span class="p">);</span>

<span class="w">                    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">migrate_count</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                        </span><span class="n">migrate_particles</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="p">,</span><span class="w"> </span><span class="n">migrate_count</span><span class="p">);</span>
<span class="w">                        </span><span class="n">converged</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">                    </span><span class="p">}</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">converged</span><span class="p">)</span><span class="w"> </span><span class="k">break</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>



   3. **非均匀网格支持** - 使用八叉树：


<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">AdaptiveGrid</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">OctreeNode</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">float3</span><span class="w"> </span><span class="n">center</span><span class="p">,</span><span class="w"> </span><span class="n">half_size</span><span class="p">;</span>
<span class="w">        </span><span class="n">OctreeNode</span><span class="o">*</span><span class="w"> </span><span class="n">children</span><span class="p">[</span><span class="mi">8</span><span class="p">];</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">particle_count</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">gpu_owner</span><span class="p">;</span>

<span class="w">        </span><span class="kt">bool</span><span class="w"> </span><span class="nf">should_refine</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">particle_count</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="n">threshold</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="o">!</span><span class="n">is_leaf</span><span class="p">();</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="kt">void</span><span class="w"> </span><span class="nf">assign_to_gpu</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">gpu_loads</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">is_leaf</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="c1">// 分配给负载最小的GPU</span>
<span class="w">                </span><span class="n">gpu_owner</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">min_element</span><span class="p">(</span><span class="n">gpu_loads</span><span class="p">,</span><span class="w"> </span><span class="n">gpu_loads</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">num_gpus</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">gpu_loads</span><span class="p">;</span>
<span class="w">                </span><span class="n">gpu_loads</span><span class="p">[</span><span class="n">gpu_owner</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">particle_count</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">child</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">children</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="n">child</span><span class="o">-&gt;</span><span class="n">assign_to_gpu</span><span class="p">(</span><span class="n">gpu_loads</span><span class="p">);</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">};</span>
<span class="p">};</span>
</code></pre></div>



   4. **容错性** - 检查点和冗余：


<div class="codehilite"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">FaultTolerantDomain</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">checkpoint</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 每个GPU保存邻居的ghost数据</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">neighbor</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">neighbors</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">backup_ghost_data</span><span class="p">[</span><span class="n">neighbor</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_ghost_data</span><span class="p">(</span><span class="n">neighbor</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// 异步写入持久存储</span>
<span class="w">        </span><span class="n">async_write_checkpoint</span><span class="p">(</span><span class="n">local_data</span><span class="p">,</span><span class="w"> </span><span class="n">backup_ghost_data</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="nf">recover_from_failure</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">failed_gpu</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 邻居GPU接管失败GPU的区域</span>
<span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">neighbors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_neighbors</span><span class="p">(</span><span class="n">failed_gpu</span><span class="p">);</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">neighbors</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">gpu</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">neighbors</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">            </span><span class="c1">// 从备份恢复ghost区域的数据</span>
<span class="w">            </span><span class="n">restore_from_backup</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span><span class="w"> </span><span class="n">failed_gpu</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// 扩展计算域</span>
<span class="w">            </span><span class="n">extend_domain</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span><span class="w"> </span><span class="n">failed_gpu</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">neighbors</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// 重新平衡负载</span>
<span class="w">        </span><span class="n">rebalance_after_failure</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>


   </details>
<ol start="6">
<li><strong>混合精度优化</strong>
   设计一个自适应混合精度物理仿真框架，在保证精度的同时最大化性能。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑误差传播、数值稳定性、硬件支持（Tensor Cores）。
   </details>
<details markdown="block">
   <summary markdown="off">答案</summary>

   ```cpp
   template&lt;typename HighPrec = double, typename LowPrec = float&gt;
   class MixedPrecisionSolver {
       // 误差估计器
       class ErrorEstimator {
           HighPrec reference_solution;
           LowPrec approximate_solution;

           float estimate_error() {
               return norm(reference_solution - HighPrec(approximate_solution)) 
                      / norm(reference_solution);
           }

           bool needs_refinement(float threshold = 1e-4) {
               return estimate_error() &gt; threshold;
           }
       };

       // 自适应精度选择
       class PrecisionSelector {
           struct RegionInfo {
               float3 min, max;
               float error_estimate;
               bool use_high_precision;
           };

           std::vector&lt;RegionInfo&gt; regions;

           void analyze_regions() {
               for (auto&amp; region : regions) {
                   // 基于物理量梯度判断
                   float gradient = compute_gradient(region);

                   // 基于条件数判断
                   float condition = estimate_condition_number(region);

                   // 决策
                   region.use_high_precision = 
                       gradient &gt; gradient_threshold ||
                       condition &gt; condition_threshold ||
                       region.error_estimate &gt; error_threshold;
               }
           }
       };

       // 混合精度矩阵运算（利用Tensor Cores）
       void mixed_precision_gemm(float* C, const half* A, const half* B, 
                                int M, int N, int K) {
           // 使用Tensor Cores进行半精度计算
           cublasGemmEx(handle,
               CUBLAS_OP_N, CUBLAS_OP_N,
               M, N, K,
               &amp;alpha,
               A, CUDA_R_16F, M,
               B, CUDA_R_16F, K,
               &amp;beta,
               C, CUDA_R_32F, M,
               CUDA_R_32F,
               CUBLAS_GEMM_DEFAULT_TENSOR_OP);
       }

       // 迭代细化求解器
       void iterative_refinement_solve(Matrix&lt;HighPrec&gt;&amp; A, 
                                     Vector&lt;HighPrec&gt;&amp; b,
                                     Vector&lt;HighPrec&gt;&amp; x) {
           // 转换为低精度
           Matrix&lt;LowPrec&gt; A_low = convert&lt;LowPrec&gt;(A);
           Vector&lt;LowPrec&gt; b_low = convert&lt;LowPrec&gt;(b);
           Vector&lt;LowPrec&gt; x_low = convert&lt;LowPrec&gt;(x);

           // 低精度LU分解
           LU&lt;LowPrec&gt; lu(A_low);

           for (int iter = 0; iter &lt; max_iterations; iter++) {
               // 计算残差（高精度）
               Vector&lt;HighPrec&gt; r = b - A * x;

               // 检查收敛
               if (norm(r) &lt; tolerance) break;

               // 低精度求解修正量
               Vector&lt;LowPrec&gt; r_low = convert&lt;LowPrec&gt;(r);
               Vector&lt;LowPrec&gt; dx_low = lu.solve(r_low);

               // 高精度更新
               x += convert&lt;HighPrec&gt;(dx_low);
           }
       }

       // 自适应时间步长with混合精度
       void adaptive_timestep() {
           float dt_high = dt;
           float dt_low = dt;

           // 用两种精度各走一步
           State&lt;HighPrec&gt; state_high = advance&lt;HighPrec&gt;(state, dt_high);
           State&lt;LowPrec&gt; state_low = advance&lt;LowPrec&gt;(state, dt_low);

           // 估计误差
           float error = estimate_error(state_high, state_low);

           if (error &gt; tolerance) {
               // 需要更高精度或更小步长
               dt *= 0.5;
               use_high_precision = true;
           } else if (error &lt; 0.1 * tolerance) {
               // 可以用更低精度或更大步长
               dt *= 1.5;
               use_high_precision = false;
           }
       }
   };
   ```
   </details>
<ol start="7">
<li><strong>SIMD优化的SPH实现</strong>
   实现一个高度优化的SPH邻居搜索和力计算，充分利用AVX-512指令集。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑数据布局、掩码操作、向量化的距离计算。
   </details>
<details markdown="block">
   <summary markdown="off">答案</summary>

   ```cpp
   class SimdSPH {
       // 16路SIMD的粒子数据（AVX-512）
       struct ParticleBlock {
           __m512 x[BLOCK_SIZE/16];
           __m512 y[BLOCK_SIZE/16];
           __m512 z[BLOCK_SIZE/16];
           __m512 vx[BLOCK_SIZE/16];
           __m512 vy[BLOCK_SIZE/16];
           __m512 vz[BLOCK_SIZE/16];
           __m512 density[BLOCK_SIZE/16];
           __m512 pressure[BLOCK_SIZE/16];
       };

       // 向量化的邻居搜索
       void find_neighbors_simd(int particle_id, std::vector&lt;int&gt;&amp; neighbors) {
           __m512 px = _mm512_set1_ps(particles.x[particle_id]);
           __m512 py = _mm512_set1_ps(particles.y[particle_id]);
           __m512 pz = _mm512_set1_ps(particles.z[particle_id]);
           __m512 h2 = _mm512_set1_ps(h * h);

           // 获取粒子所在的网格单元
           int3 cell = get_cell(particle_id);

           // 遍历27个邻居单元
           for (int dz = -1; dz &lt;= 1; dz++) {
               for (int dy = -1; dy &lt;= 1; dy++) {
                   for (int dx = -1; dx &lt;= 1; dx++) {
                       int3 ncell = cell + make_int3(dx, dy, dz);
                       int start = cell_start[ncell];
                       int end = cell_end[ncell];

                       // SIMD处理16个粒子
                       for (int i = start; i &lt; end; i += 16) {
                           // 加载16个粒子位置
                           __m512 qx = _mm512_load_ps(&amp;particles.x[i]);
                           __m512 qy = _mm512_load_ps(&amp;particles.y[i]);
                           __m512 qz = _mm512_load_ps(&amp;particles.z[i]);

                           // 计算距离平方
                           __m512 dx = _mm512_sub_ps(px, qx);
                           __m512 dy = _mm512_sub_ps(py, qy);
                           __m512 dz = _mm512_sub_ps(pz, qz);

                           __m512 r2 = _mm512_fmadd_ps(dx, dx,
                                       _mm512_fmadd_ps(dy, dy,
                                       _mm512_mul_ps(dz, dz)));

                           // 生成掩码：r2 &lt; h2
                           __mmask16 mask = _mm512_cmp_ps_mask(r2, h2, _CMP_LT_OQ);

                           // 压缩存储邻居索引
                           if (mask != 0) {
                               int indices[16];
                               for (int j = 0; j &lt; 16; j++) {
                                   indices[j] = i + j;
                               }

                               // 使用compress存储有效邻居
                               __m512i idx = _mm512_load_epi32(indices);
                               __m512i compressed = _mm512_maskz_compress_epi32(mask, idx);

                               // 存储到邻居列表
                               int count = _mm_popcnt_u32(mask);
                               _mm512_storeu_epi32(&amp;neighbors[neighbors.size()], compressed);
                               neighbors.resize(neighbors.size() + count);
                           }
                       }
                   }
               }
           }
       }

       // 向量化的密度计算
       void compute_density_simd() {
           const __m512 factor = _mm512_set1_ps(mass * poly6_constant);

           #pragma omp parallel for
           for (int i = 0; i &lt; particle_count; i += 16) {
               __m512 density_sum = _mm512_setzero_ps();

               // 对每个粒子的邻居进行向量化处理
               for (int j = 0; j &lt; 16; j++) {
                   int pid = i + j;
                   if (pid &gt;= particle_count) break;

                   __m512 px = _mm512_set1_ps(particles.x[pid]);
                   __m512 py = _mm512_set1_ps(particles.y[pid]);
                   __m512 pz = _mm512_set1_ps(particles.z[pid]);

                   // 处理邻居（已对齐到16的倍数）
                   int neighbor_count = neighbor_lists[pid].size();
                   for (int k = 0; k &lt; neighbor_count; k += 16) {
                       // 加载16个邻居
                       __m512i indices = _mm512_load_epi32(&amp;neighbor_lists[pid][k]);

                       // Gather邻居位置
                       __m512 qx = _mm512_i32gather_ps(indices, particles.x, 4);
                       __m512 qy = _mm512_i32gather_ps(indices, particles.y, 4);
                       __m512 qz = _mm512_i32gather_ps(indices, particles.z, 4);

                       // 计算核函数值
                       __m512 dx = _mm512_sub_ps(px, qx);
                       __m512 dy = _mm512_sub_ps(py, qy);
                       __m512 dz = _mm512_sub_ps(pz, qz);

                       __m512 r2 = _mm512_fmadd_ps(dx, dx,
                                   _mm512_fmadd_ps(dy, dy,
                                   _mm512_mul_ps(dz, dz)));

                       // W = (h² - r²)³（简化的poly6核）
                       __m512 h2 = _mm512_set1_ps(h * h);
                       __m512 diff = _mm512_sub_ps(h2, r2);
                       __m512 diff2 = _mm512_mul_ps(diff, diff);
                       __m512 w = _mm512_mul_ps(diff2, diff);

                       // 累加密度贡献
                       density_sum = _mm512_fmadd_ps(factor, w, density_sum);
                   }
               }

               // 水平归约并存储
               _mm512_store_ps(&amp;particles.density[i], density_sum);
           }
       }

       // 向量化的压力计算
       void compute_forces_simd() {
           #pragma omp parallel for schedule(dynamic, 16)
           for (int i = 0; i &lt; particle_count; i++) {
               __m512 fx = _mm512_setzero_ps();
               __m512 fy = _mm512_setzero_ps(); 
               __m512 fz = _mm512_setzero_ps();

               __m512 pi = _mm512_set1_ps(particles.pressure[i]);
               __m512 di = _mm512_set1_ps(particles.density[i]);

               // 处理所有邻居
               process_neighbors_forces_simd(i, fx, fy, fz, pi, di);

               // 归约力到标量
               particles.fx[i] = _mm512_reduce_add_ps(fx);
               particles.fy[i] = _mm512_reduce_add_ps(fy);
               particles.fz[i] = _mm512_reduce_add_ps(fz);
           }
       }
   };
   ```
   </details>
<ol start="8">
<li><strong>能耗感知的性能优化</strong>
   设计一个能够在性能和能耗之间自动平衡的物理引擎调度器。</li>
</ol>
<details markdown="block">
   <summary markdown="off">提示</summary>
   考虑DVFS、任务调度、精度调整、硬件特性。
   </details>
<details markdown="block">
   <summary markdown="off">答案</summary>

   ```cpp
   class EnergyAwareScheduler {
       // 能耗模型
       struct PowerModel {
           // 动态功耗：P = C × V² × f
           float capacitance;
           float voltage;
           float frequency;

           // 静态功耗
           float static_power;

           float compute_power() {
               return capacitance * voltage * voltage * frequency + static_power;
           }

           // 能效：Performance per Watt
           float efficiency(float performance) {
               return performance / compute_power();
           }
       };

       // DVFS控制器
       class DVFSController {
           struct FrequencyLevel {
               float frequency;
               float voltage;
               float performance_scale;
           };

           std::vector&lt;FrequencyLevel&gt; levels;
           int current_level;

           void adjust_frequency(float target_fps, float current_fps, float power_budget) {
               // PID控制器
               float error = target_fps - current_fps;
               float power = measure_power();

               if (power &gt; power_budget) {
                   // 超过功耗预算，降频
                   decrease_frequency();
               } else if (error &gt; 0 &amp;&amp; power &lt; 0.9 * power_budget) {
                   // 性能不足且有功耗余量，升频
                   increase_frequency();
               }

               // 考虑温度限制
               float temp = read_temperature();
               if (temp &gt; THERMAL_LIMIT) {
                   current_level = std::min(current_level, get_safe_level(temp));
               }
           }
       };

       // 任务能效调度
       class TaskScheduler {
           struct Task {
               std::function&lt;void()&gt; work;
               float expected_time;
               float expected_energy;
               int preferred_core;  // 大核/小核偏好
           };

           // 大小核调度
           void schedule_heterogeneous(std::vector&lt;Task&gt;&amp; tasks) {
               // 按能效比排序
               std::sort(tasks.begin(), tasks.end(), 
                   [](const Task&amp; a, const Task&amp; b) {
                       return a.expected_time / a.expected_energy &gt; 
                              b.expected_time / b.expected_energy;
                   });

               // 能效高的任务分配到小核
               for (auto&amp; task : tasks) {
                   if (task.expected_energy &lt; ENERGY_THRESHOLD) {
                       task.preferred_core = LITTLE_CORE;
                   } else {
                       task.preferred_core = BIG_CORE;
                   }
               }

               // 动态迁移
               monitor_and_migrate(tasks);
           }

           void monitor_and_migrate(std::vector&lt;Task&gt;&amp; tasks) {
               for (auto&amp; task : tasks) {
                   float actual_energy = measure_task_energy(task);

                   // 如果实际能耗与预期差异大，迁移到合适的核
                   if (std::abs(actual_energy - task.expected_energy) &gt; THRESHOLD) {
                       migrate_task(task);
                   }
               }
           }
       };

       // 自适应精度控制
       class AdaptivePrecision {
           enum PrecisionLevel {
               FP64,     // 最高精度，最高能耗
               FP32,     // 标准精度
               FP16,     // 半精度
               INT8      // 量化，最低能耗
           };

           PrecisionLevel select_precision(float error_tolerance, float power_budget) {
               struct Config {
                   PrecisionLevel level;
                   float relative_power;
                   float max_error;
               };

               Config configs[] = {
                   {FP64, 1.0,   1e-15},
                   {FP32, 0.5,   1e-7},
                   {FP16, 0.25,  1e-3},
                   {INT8, 0.1,   1e-2}
               };

               // 选择满足精度要求的最低能耗配置
               for (auto&amp; config : configs) {
                   if (config.max_error &lt;= error_tolerance &amp;&amp;
                       config.relative_power &lt;= power_budget) {
                       return config.level;
                   }
               }

               return FP32;  // 默认
           }
       };

       // 能耗感知的负载均衡
       class PowerAwareLoadBalancer {
           void balance_with_power_constraint(float total_power_budget) {
               int num_gpus = get_gpu_count();
               std::vector&lt;float&gt; gpu_powers(num_gpus);
               std::vector&lt;float&gt; gpu_performances(num_gpus);

               // 测量每个GPU的功耗和性能
               for (int i = 0; i &lt; num_gpus; i++) {
                   gpu_powers[i] = measure_gpu_power(i);
                   gpu_performances[i] = measure_gpu_performance(i);
               }

               // 优化问题：最大化总性能，约束总功耗
               // maximize: Σ performance[i] × active[i]
               // subject to: Σ power[i] × active[i] ≤ power_budget

               // 贪心算法：按性能功耗比排序
               std::vector&lt;int&gt; indices(num_gpus);
               std::iota(indices.begin(), indices.end(), 0);

               std::sort(indices.begin(), indices.end(),
                   [&amp;](int a, int b) {
                       return gpu_performances[a] / gpu_powers[a] &gt;
                              gpu_performances[b] / gpu_powers[b];
                   });

               // 选择GPU直到达到功耗预算
               float used_power = 0;
               std::vector&lt;bool&gt; active(num_gpus, false);

               for (int idx : indices) {
                   if (used_power + gpu_powers[idx] &lt;= total_power_budget) {
                       active[idx] = true;
                       used_power += gpu_powers[idx];
                   }
               }

               // 重新分配工作负载
               redistribute_work(active);
           }
       };

       // 主调度循环
       void energy_aware_schedule() {
           while (running) {
               // 读取系统状态
               SystemState state = read_system_state();

               // 预测下一帧的计算需求
               WorkloadPrediction prediction = predict_workload();

               // 优化能效
               OptimalConfig config = optimize_energy_efficiency(
                   state, prediction, constraints);

               // 应用配置
               apply_configuration(config);

               // 执行仿真步
               execute_simulation_step();

               // 记录能耗数据用于future优化
               record_energy_metrics();
           }
       }
   };
   ```
   </details>
<h2 id="_6">常见陷阱与错误</h2>
<ol>
<li>
<p><strong>伪共享</strong>：多线程访问同一缓存行的不同数据导致性能严重下降。使用padding或__cacheline_aligned避免。</p>
</li>
<li>
<p><strong>内存带宽饱和</strong>：盲目增加线程数不一定提升性能，要考虑内存带宽限制。</p>
</li>
<li>
<p><strong>GPU占用率陷阱</strong>：100%占用率不等于最佳性能，要平衡占用率和寄存器使用。</p>
</li>
<li>
<p><strong>分支发散</strong>：GPU中的条件分支会导致warp内线程执行不同路径，严重影响性能。</p>
</li>
<li>
<p><strong>原子操作竞争</strong>：大量线程竞争同一原子变量会造成串行化，考虑使用归约树。</p>
</li>
<li>
<p><strong>NUMA远程访问</strong>：未考虑NUMA拓扑的内存分配会导致远程访问，性能下降50%以上。</p>
</li>
<li>
<p><strong>过度优化</strong>：不要优化非热点代码，先profile再优化。</p>
</li>
<li>
<p><strong>缓存抖动</strong>：工作集略大于缓存容量时性能断崖式下跌，考虑分块或流式处理。</p>
</li>
</ol>
<h2 id="_7">最佳实践检查清单</h2>
<h3 id="_8">设计阶段</h3>
<ul>
<li>[ ] 识别计算密集vs内存密集的部分</li>
<li>[ ] 选择合适的并行粒度</li>
<li>[ ] 设计缓存友好的数据结构</li>
<li>[ ] 考虑NUMA和GPU内存层次</li>
<li>[ ] 预估通信开销</li>
</ul>
<h3 id="_9">实现阶段</h3>
<ul>
<li>[ ] 数据对齐到缓存行边界</li>
<li>[ ] 使用SoA布局提高向量化效率</li>
<li>[ ] 避免false sharing</li>
<li>[ ] 最小化同步点</li>
<li>[ ] 合并内存访问（GPU）</li>
</ul>
<h3 id="_10">优化阶段</h3>
<ul>
<li>[ ] Profile识别真正的瓶颈</li>
<li>[ ] 测量并优化缓存命中率</li>
<li>[ ] 检查向量化效率</li>
<li>[ ] 验证负载均衡</li>
<li>[ ] 监控功耗和温度</li>
</ul>
<h3 id="_11">调试阶段</h3>
<ul>
<li>[ ] 使用内存检查工具（valgrind、cuda-memcheck）</li>
<li>[ ] 检查数据竞争（ThreadSanitizer）</li>
<li>[ ] 验证数值精度</li>
<li>[ ] 测试极端情况（空数据、超大规模）</li>
<li>[ ] 检查内存泄漏</li>
</ul>
<h3 id="_12">部署阶段</h3>
<ul>
<li>[ ] 针对目标硬件调优</li>
<li>[ ] 设置合理的默认参数</li>
<li>[ ] 提供性能调节选项</li>
<li>[ ] 记录性能特征</li>
<li>[ ] 监控生产环境表现</li>
</ul>
            </article>
            
            <nav class="page-nav"><a href="./chapter8.html" class="nav-link prev">← 第八章：混合欧拉-拉格朗日视角（2）：物质点法</a><a href="./chapter10.html" class="nav-link next">第十章：可微编程与机器学习 →</a></nav>
        </main>
    </div>
</body>
</html>